{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpsonsCharRecog_LittleVGG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMiEqRWnbb9uwrrX+WngD+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aparna-U-Nair/Simpsons-Character-Recognition/blob/master/SimpsonsCharRecog_LittleVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQCeuIbNR4wG",
        "outputId": "5df31323-003e-4e42-f035-25b2f7630f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9bermaai_nz"
      },
      "source": [
        "from os.path import join, isfile\n",
        "from os import listdir\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import sys\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "craWj8-AlAC0"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPool2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.advanced_activations import ELU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctdouceHln0Y",
        "outputId": "a5178f0b-94dc-49d6-e82f-df07c60e9681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_classes = 20\n",
        "rows,cols = 32,32\n",
        "batch_size = 32\n",
        "\n",
        "train_path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/train/\"\n",
        "test_path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/test\"\n",
        "\n",
        "#Using ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range =30,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range = 0.3,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\",\n",
        "    rescale = 1./255,\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(rows,cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(rows,cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19558 images belonging to 20 classes.\n",
            "Found 990 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkfnycnpU6t",
        "outputId": "694b5da3-3111-48d6-98ae-a64672c19eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Create the VGG9 model\n",
        "model = Sequential()\n",
        "\n",
        "#1st Conv-Relu Layer\n",
        "model.add(Conv2D(64,(3,3),input_shape = (rows,cols,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#2nd Conv-Relu Layer\n",
        "model.add(Conv2D(64,(3,3),input_shape = (rows,cols,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Maxpooling with Dropout Layer\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#3rd Conv-Relu Layer\n",
        "model.add(Conv2D(128,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#4th Conv-Relu Layer\n",
        "model.add(Conv2D(128,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Maxpooling with Dropout Layer\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#5th Conv-Relu Layer\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#6th Conv-Relu Layer\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Maxpooling with Dropout Layer\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#1st FC layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd FC layer\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#Final output layer\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                5140      \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 20)                0         \n",
            "=================================================================\n",
            "Total params: 2,270,804\n",
            "Trainable params: 2,267,988\n",
            "Non-trainable params: 2,816\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toC95aWMtSy_",
        "outputId": "84a92a28-97c8-4379-ee7d-72f8aadf6079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "#Model Visualization\n",
        "%matplotlib inline\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib.image import mpimg\n",
        "plot_model(model,to_file = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/VGG9.png\", show_shapes = True, show_layer_names = True)\n",
        "img = mpimg.imread(\"/content/gdrive/My Drive/Colab Notebooks/simpsons/VGG9.png\")\n",
        "plt.figure(figsize=(100,70))\n",
        "plot = plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-038e273b3751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/My Drive/Colab Notebooks/simpsons/VGG9.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Colab Notebooks/simpsons/VGG9.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'mpimg'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUC5JwwzuyJq",
        "outputId": "4a7a089f-a0cb-40f2-a07d-9d2d401d5eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Train the VGG9 model\n",
        "\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/model.{epoch:02d}-{val_loss:.2f}.h5\",\n",
        "                             monitor = \"val_loss\",\n",
        "                             mode = \"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose = 1)\n",
        "es = EarlyStopping(monitor = \"val_loss\",\n",
        "                   min_delta = 0,\n",
        "                   patience = 3,\n",
        "                   verbose = 1,\n",
        "                   restore_best_weights = True)\n",
        "lr = ReduceLROnPlateau(monitor = \"val_loss\",\n",
        "                       factor = 0.2,\n",
        "                       min_delta = 0.00001,\n",
        "                       patience = 3,\n",
        "                       verbose = 1)\n",
        "\n",
        "callbacks = [checkpoint, es, lr]\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = Adam(lr = 0.01),\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "#sample size from data generator out\n",
        "train_samples = 19548\n",
        "test_samples = 990\n",
        "epochs = 20\n",
        "\n",
        "hist = model.fit_generator(train_generator,\n",
        "                           steps_per_epoch = train_samples // batch_size,\n",
        "                           epochs = epochs,\n",
        "                           callbacks = callbacks,\n",
        "                           validation_data = test_generator,\n",
        "                           validation_steps = test_samples//batch_size\n",
        "                           )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "610/610 [==============================] - ETA: 0s - loss: 2.8840 - accuracy: 0.1670\n",
            "Epoch 00001: val_loss improved from inf to 2.64472, saving model to /content/gdrive/My Drive/Colab Notebooks/simpsons/model.01-2.64.h5\n",
            "610/610 [==============================] - 5867s 10s/step - loss: 2.8840 - accuracy: 0.1670 - val_loss: 2.6447 - val_accuracy: 0.2115\n",
            "Epoch 2/20\n",
            "610/610 [==============================] - ETA: 0s - loss: 2.2980 - accuracy: 0.2926\n",
            "Epoch 00002: val_loss improved from 2.64472 to 2.55723, saving model to /content/gdrive/My Drive/Colab Notebooks/simpsons/model.02-2.56.h5\n",
            "610/610 [==============================] - 84s 138ms/step - loss: 2.2980 - accuracy: 0.2926 - val_loss: 2.5572 - val_accuracy: 0.2990\n",
            "Epoch 3/20\n",
            "407/610 [===================>..........] - ETA: 24s - loss: 1.9185 - accuracy: 0.4041"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y2RapwwpKQe"
      },
      "source": [
        "# model.save(\"/content/gdrive/My Drive/Colab Notebooks/simpsons/last_vgg9.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M9zDm26y25c"
      },
      "source": [
        "#Performance Analysis\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Recreating the test datagen by keeping shuffle = False\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(rows,cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle = False)\n",
        "\n",
        "labels = val_generator.class_indices\n",
        "labels = {v:k for k,v in labels.items()}\n",
        "classes= list(labels.values())\n",
        "\n",
        "train_samples = 19548\n",
        "test_samples = 990\n",
        "\n",
        "y_pred = model.predict_generator(val_generator, test_samples//batch_size+1)\n",
        "y_pred = np.argmax(y_pred,axis = 1)\n",
        "\n",
        "cm = confusion_matrix(val_generator.classes, y_pred)\n",
        "print(\"CM\")\n",
        "cm\n",
        "print(\"Class Report\")\n",
        "classification_report(val_generator.classes, y_pred, target_names = classes)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm,interpolation=\"nearest\")\n",
        "plt.colorbar()\n",
        "tick_marks = len(classes)\n",
        "_ = plt.xticks(tick_marks,classes, rotation =90 )\n",
        "_ = plt.yticks(tick_marks, classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmbCUVz4358C"
      },
      "source": [
        "#Testing some random images\n",
        "def draw_test_img(name,pred,input_img,true_label):\n",
        "  black = [0,0,0]\n",
        "  final_img = cv2.copyMakeBorder(input_img,160,0,0,300, cv2.BORDER_CONSTANT, value =BLACK)\n",
        "  cv2.putText(final_img,\"Predicted: \"+pred,(20,60),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0),2)\n",
        "  cv2.putText(final_img,\"True: \"+true_label,(20,120),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0),2)\n",
        "  cv2.imshow(name,final_img)\n",
        "    \n",
        "def get_rand_img(path, wid, hei):\n",
        "\n",
        "\n",
        "width, height = 32,32\n",
        "files= []\n",
        "preds = []\n",
        "true_lab = []\n",
        "\n",
        "for i in range(5):\n",
        "  path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/validation/\"\n",
        "  img, fin_path, true_label = get_rand_img(path, width, height)\n",
        "  files.append(fin_path)\n",
        "  true_lab.append(true_label)\n",
        "  x = image.img_to_array(img)\n",
        "  x = x* 1./255\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "  images= np.vstack([x])\n",
        "  classes = model.predict_classes(images, batch_size=10)\n",
        "  preds.append(classes)\n",
        "\n",
        "for i in range(len(files)):\n",
        "  image = cv2.imread(files[i])\n",
        "  image = cv2.resize(image, None, fx = 5, fy = 5, interpolation = cv2.INTER_CUBIC)\n",
        "  draw_test(\"Prediction\",)\n",
        "  \n",
        "  rand_num = np.random.randint(0,len(X_test))\n",
        "  rand_img = X_test[rand_num]\n",
        "  img = cv2.resize(rand_img,None, fx=4,fy=4, interpolation=cv2.INTER_CUBIC)\n",
        "  img = img.reshape(1,X_test[0].shape[0], X_test[1].shape[0],1)\n",
        "  \n",
        "  out = str(mnist_model.predict_classes(img,1,verbose=0)[0])\n",
        "  draw_test_img(out, img)\n",
        "    \n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}