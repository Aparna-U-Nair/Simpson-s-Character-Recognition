{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpsonsCharRecog_LittleVGG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoNnjhLAz686dHIHNl/KDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aparna-U-Nair/Simpsons-Character-Recognition/blob/master/SimpsonsCharRecog_LittleVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQCeuIbNR4wG",
        "outputId": "1f420ece-ffa1-40a6-dfa1-9b93ccac5b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9bermaai_nz"
      },
      "source": [
        "from os.path import join, isfile\n",
        "from os import listdir\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import sys\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "craWj8-AlAC0"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPool2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.advanced_activations import ELU"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctdouceHln0Y",
        "outputId": "0e5c4438-8102-415b-bf3d-83031cce4922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_classes = 20\n",
        "rows,cols = 32,32\n",
        "batch_size = 32\n",
        "\n",
        "train_path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/train/\"\n",
        "test_path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/test\"\n",
        "\n",
        "#Using ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range =30,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range = 0.3,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\",\n",
        "    rescale = 1./255,\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(rows,cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(rows,cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19558 images belonging to 20 classes.\n",
            "Found 990 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkfnycnpU6t",
        "outputId": "694b5da3-3111-48d6-98ae-a64672c19eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Create the VGG9 model\n",
        "model = Sequential()\n",
        "\n",
        "#1st Conv-Relu Layer\n",
        "model.add(Conv2D(64,(3,3),input_shape = (rows,cols,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#2nd Conv-Relu Layer\n",
        "model.add(Conv2D(64,(3,3),input_shape = (rows,cols,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Maxpooling with Dropout Layer\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#3rd Conv-Relu Layer\n",
        "model.add(Conv2D(128,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#4th Conv-Relu Layer\n",
        "model.add(Conv2D(128,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Maxpooling with Dropout Layer\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#5th Conv-Relu Layer\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#6th Conv-Relu Layer\n",
        "model.add(Conv2D(256,(3,3),padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Maxpooling with Dropout Layer\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#1st FC layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd FC layer\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#Final output layer\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                5140      \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 20)                0         \n",
            "=================================================================\n",
            "Total params: 2,270,804\n",
            "Trainable params: 2,267,988\n",
            "Non-trainable params: 2,816\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toC95aWMtSy_"
      },
      "source": [
        "#Model Visualization\n",
        "# %matplotlib inline\n",
        "# from keras.utils.vis_utils import plot_model\n",
        "# from matplotlib.image import mpimg\n",
        "# plot_model(model,to_file = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/VGG9.png\", show_shapes = True, show_layer_names = True)\n",
        "# img = mpimg.imread(\"/content/gdrive/My Drive/Colab Notebooks/simpsons/VGG9.png\")\n",
        "# plt.figure(figsize=(100,70))\n",
        "# plot = plt.imshow(img)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUC5JwwzuyJq"
      },
      "source": [
        "# Train the VGG9 model\n",
        "\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/model.{epoch:02d}-{val_loss:.2f}.h5\",\n",
        "                             monitor = \"val_loss\",\n",
        "                             mode = \"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose = 1)\n",
        "es = EarlyStopping(monitor = \"val_loss\",\n",
        "                   min_delta = 0,\n",
        "                   patience = 3,\n",
        "                   verbose = 1,\n",
        "                   restore_best_weights = True)\n",
        "lr = ReduceLROnPlateau(monitor = \"val_loss\",\n",
        "                       factor = 0.2,\n",
        "                       min_delta = 0.00001,\n",
        "                       patience = 3,\n",
        "                       verbose = 1)\n",
        "\n",
        "callbacks = [checkpoint, es, lr]\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = Adam(lr = 0.01),\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "#sample size from data generator out\n",
        "train_samples = 19548\n",
        "test_samples = 990\n",
        "epochs = 20\n",
        "\n",
        "hist = model.fit_generator(train_generator,\n",
        "                           steps_per_epoch = train_samples // batch_size,\n",
        "                           epochs = epochs,\n",
        "                           callbacks = callbacks,\n",
        "                           validation_data = test_generator,\n",
        "                           validation_steps = test_samples//batch_size\n",
        "                           )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M9zDm26y25c"
      },
      "source": [
        "#Performance Analysis\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Recreating the test datagen by keeping shuffle = False\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(rows,cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle = False)\n",
        "\n",
        "labels = val_generator.class_indices\n",
        "labels = {v:k for k,v in labels.items()}\n",
        "classes= list(labels.values())\n",
        "\n",
        "train_samples = 19548\n",
        "test_samples = 990\n",
        "\n",
        "y_pred = model.predict_generator(val_generator, test_samples//batch_size+1)\n",
        "y_pred = np.argmax(y_pred,axis = 1)\n",
        "\n",
        "cm = confusion_matrix(val_generator.classes, y_pred)\n",
        "print(\"CM\")\n",
        "cm\n",
        "print(\"Class Report\")\n",
        "classification_report(val_generator.classes, y_pred, target_names = classes)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm,interpolation=\"nearest\")\n",
        "plt.colorbar()\n",
        "tick_marks = len(classes)\n",
        "_ = plt.xticks(tick_marks,classes, rotation =90 )\n",
        "_ = plt.yticks(tick_marks, classes)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXqikfUKWx-Q",
        "outputId": "f80124eb-dbb4-4fb3-ba42-d8028552112a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lmodel = load_model(\"/content/gdrive/My Drive/Colab Notebooks/simpsons/weights.best.hdf5\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmbCUVz4358C"
      },
      "source": [
        "# #Testing some random images\n",
        "# def draw_test_img(name,pred,input_img,true_label):\n",
        "#   black = [0,0,0]\n",
        "#   final_img = cv2.copyMakeBorder(input_img,160,0,0,300, cv2.BORDER_CONSTANT, value =BLACK)\n",
        "#   cv2.putText(final_img,\"Predicted: \"+pred,(20,60),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0),2)\n",
        "#   cv2.putText(final_img,\"True: \"+true_label,(20,120),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0),2)\n",
        "#   cv2.imshow(name,final_img)\n",
        "    \n",
        "# def get_rand_img(path, wid, hei):\n",
        "#   #Load a random image from the test folder\n",
        "#   folders = list(filter(lambda x: os.path.isdir(os.path.join(path,x)),os.listdir(path)))\n",
        "#   rand_dir = np.random.randint(len(folders))\n",
        "#   path_class = folders[rand_dir]\n",
        "#   file_path = path+path_class\n",
        "#   file_names = [f for f in listdir(file_path) if isfile(join(file_path,f))]\n",
        "#   rand_idx = np.random.randint(len(file_names))\n",
        "#   img_name = file_names[rand_idx]\n",
        "#   final_path = file_path + \"/\" + img_name\n",
        "#   return image.load_img(final_path, target_size = (width, height)), final_path, path_class\n",
        "\n",
        "\n",
        "# width, height = 32,32\n",
        "# files= []\n",
        "# preds = []\n",
        "# true_lab = []\n",
        "\n",
        "# for i in range(5):\n",
        "#   path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/test/\"\n",
        "#   img, fin_path, true_label = get_rand_img(path, width, height)\n",
        "#   files.append(fin_path)\n",
        "#   true_lab.append(true_label)\n",
        "#   x = image.img_to_array(img)\n",
        "#   x = x* 1./255\n",
        "#   x = np.expand_dims(x, axis = 0)\n",
        "#   images= np.vstack([x])\n",
        "#   classes = lmodel.predict_classes(images, batch_size=10)\n",
        "#   preds.append(classes)\n",
        "\n",
        "# for i in range(len(files)):\n",
        "#   image = cv2.imread(files[i])\n",
        "#   image = cv2.resize(image, None, fx = 5, fy = 5, interpolation = cv2.INTER_CUBIC)\n",
        "#   draw_test(\"Prediction\",class_labels[preds[i][0]], image, true_lab[i])\n",
        "    \n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__7tmcjMbosp"
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def model_predict(img_path, model):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "    # Preprocessing the image\n",
        "    x = image.img_to_array(img)\n",
        "    # x = np.true_divide(x, 255)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Be careful how your trained model deals with the input\n",
        "    # otherwise, it won't make correct prediction!\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    preds = model.predict(x)\n",
        "    return preds\n",
        "file_path = \"/content/gdrive/My Drive/Colab Notebooks/simpsons/test/chief_wiggum/chief_wiggum_13.jpg\"\n",
        "preds = model_predict(file_path, lmodel)\n",
        "pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\n",
        "result = str(pred_class[0][0][1])               # Convert to string\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}